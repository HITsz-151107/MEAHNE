{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "italic-devil",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_adjlist_LastFM(adjlist, edge_metapath_indices, samples=None, exclude=None, offset=None, mode=None):\n",
    "    edges = []\n",
    "    nodes = set()\n",
    "    result_indices = []\n",
    "    #print(offset)\n",
    "    #print(exclude)\n",
    "    for row, indices in zip(adjlist, edge_metapath_indices):\n",
    "        row_parsed = list(map(int, row.split(' ')))\n",
    "        nodes.add(row_parsed[0])\n",
    "        if len(row_parsed) > 1:\n",
    "            # sampling neighbors\n",
    "            if samples is None:\n",
    "                if exclude is not None:\n",
    "                    if mode == 0:\n",
    "                        mask = [False if [u1, a1 - offset] in exclude or [u2, a2 - offset] in exclude else True for u1, a1, u2, a2 in indices[:, [0, 1, -1, -2]]]\n",
    "                    else:\n",
    "                        mask = [False if [u1, a1 - offset] in exclude or [u2, a2 - offset] in exclude else True for a1, u1, a2, u2 in indices[:, [0, 1, -1, -2]]]\n",
    "                    neighbors = np.array(row_parsed[1:])[mask]\n",
    "                    result_indices.append(indices[mask])\n",
    "                else:\n",
    "                    neighbors = row_parsed[1:]\n",
    "                    result_indices.append(indices)\n",
    "            else:\n",
    "                # undersampling frequent neighbors\n",
    "                unique, counts = np.unique(row_parsed[1:], return_counts=True)\n",
    "                p = []\n",
    "                for count in counts:\n",
    "                    p += [(count ** (3 / 4)) / count] * count\n",
    "                p = np.array(p)\n",
    "                p = p / p.sum()\n",
    "                samples = min(samples, len(row_parsed) - 1)\n",
    "                sampled_idx = np.sort(np.random.choice(len(row_parsed) - 1, samples, replace=False, p=p))\n",
    "                if exclude is not None:\n",
    "                    if mode == 0:\n",
    "                        mask = [False if [u1, a1 - offset] in exclude or [u2, a2 - offset] in exclude else True for u1, a1, u2, a2 in indices[sampled_idx][:, [0, 1, -1, -2]]]\n",
    "                    else:\n",
    "                        mask = [False if [u1, a1 - offset] in exclude or [u2, a2 - offset] in exclude else True for a1, u1, a2, u2 in indices[sampled_idx][:, [0, 1, -1, -2]]]\n",
    "                    neighbors = np.array([row_parsed[i + 1] for i in sampled_idx])[mask]\n",
    "                    result_indices.append(indices[sampled_idx][mask])\n",
    "                else:\n",
    "                    neighbors = [row_parsed[i + 1] for i in sampled_idx]\n",
    "                    result_indices.append(indices[sampled_idx])\n",
    "        else:\n",
    "            neighbors = [row_parsed[0]]\n",
    "            indices = np.array([[row_parsed[0]] * indices.shape[1]])\n",
    "            if mode == 1:\n",
    "                indices += offset\n",
    "            result_indices.append(indices)\n",
    "        for dst in neighbors:\n",
    "            nodes.add(dst)\n",
    "            edges.append((row_parsed[0], dst))\n",
    "    nodes=sorted(nodes)    \n",
    "   # print(nodes)\n",
    "    if mode==1:\n",
    "        node_list=[offset+i for i in nodes]\n",
    "    else:\n",
    "        node_list=[i for i in nodes]\n",
    " #   print(node_list)    \n",
    "    mapping = {map_from: map_to for map_to, map_from in enumerate(sorted(nodes))}\n",
    "    edges = list(map(lambda tup: (mapping[tup[0]], mapping[tup[1]]), edges))\n",
    "    result_indices = np.vstack(result_indices)\n",
    "    return edges, result_indices, len(nodes), mapping,node_list\n",
    "\n",
    "\n",
    "def parse_minibatch_LastFM(adjlists_ua, edge_metapath_indices_list_ua, user_artist_batch, device, samples=None, use_masks=None, offset=None):\n",
    "    g_lists = [[], []]\n",
    "    result_indices_lists = [[], []]\n",
    "    idx_batch_mapped_lists = [[], []]\n",
    "    node_list=[[],[]]\n",
    "    for mode, (adjlists, edge_metapath_indices_list) in enumerate(zip(adjlists_ua, edge_metapath_indices_list_ua)):\n",
    "        for adjlist, indices, use_mask in zip(adjlists, edge_metapath_indices_list, use_masks[mode]):\n",
    "     #       print(offset)\n",
    "            if use_mask:\n",
    "                edges, result_indices, num_nodes, mapping,nodes = parse_adjlist_LastFM(\n",
    "                    [adjlist[row[mode]] for row in user_artist_batch], [indices[row[mode]] for row in user_artist_batch], samples, user_artist_batch, offset, mode)\n",
    "            else:\n",
    "                edges, result_indices, num_nodes, mapping,nodes = parse_adjlist_LastFM(\n",
    "                    [adjlist[row[mode]] for row in user_artist_batch], [indices[row[mode]] for row in user_artist_batch], samples, offset=offset, mode=mode)\n",
    "            \n",
    "         #   num_edges=len(edges)\n",
    "            \n",
    "        #    print(edges)\n",
    "       #     print(mapping)\n",
    "      #      z=np.random.choice(np.arange(num_edges),int(0.9*num_edges),replace=False)\n",
    "      #      d_edges=[edges[i] for i in z]\n",
    "      #      result_indices=result_indices[z]\n",
    "            d_edges=edges\n",
    "            g = dgl.DGLGraph(multigraph=True)\n",
    "            g.add_nodes(num_nodes)                \n",
    "            if len(d_edges)>0:\n",
    "                sorted_index=sorted(range(len(d_edges)),key=lambda i :d_edges[i])\n",
    "                g.add_edges(*list(zip(*[(d_edges[i][1],d_edges[i][0]) for i in sorted_index]))) \n",
    "                d_result_indices = torch.LongTensor(result_indices[sorted_index]).to(device)\n",
    "                    \n",
    "            else:\n",
    "                d_result_indices=torch.LongTensor(result_indices).to(device)\n",
    "            g=g.to(device)\n",
    "            g_lists[mode].append(g)\n",
    "            result_indices_lists[mode].append(d_result_indices)\n",
    "            idx_batch_mapped_lists[mode].append(np.array([mapping[row[mode]] for row in user_artist_batch]))       \n",
    "            nodes=torch.tensor(nodes).to(device)\n",
    "   #         print(mode)\n",
    "   #         print(nodes)\n",
    "            node_list[mode].append(nodes)\n",
    "    return g_lists, result_indices_lists, idx_batch_mapped_lists,node_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-newcastle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:workspace] *",
   "language": "python",
   "name": "conda-env-workspace-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
