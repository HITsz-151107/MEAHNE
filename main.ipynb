{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dynamic-jerusalem",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import pickle\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "from dgl.nn.pytorch import edge_softmax\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "measured-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils.ipynb\n",
    "%run semantic-attention.ipynb\n",
    "%run read_dataset.ipynb\n",
    "%run multi-metapath-fusion.ipynb\n",
    "%run model.ipynb\n",
    "%run data2graph.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-adolescent",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ntype = 3\n",
    "dropout_rate = 0.5\n",
    "lr = 0.005\n",
    "weight_decay = 0.001\n",
    "    \n",
    "    #etypes_lists = [[[0, 1],[0, 2, 3, 1]],\n",
    "     #               [[1, 0],[2, 3]]\n",
    "etypes_lists = [[[0, 1],[0, 2, 3, 1],[4,None,5]],\n",
    "                [[1, 0],[2, 3],[2, None, 3]]]\n",
    "use_masks = [[True, True],\n",
    "             [True, False]]\n",
    "no_masks = [[False] * 3, [False] * 3]\n",
    "    #use_masks = [[True, True, False],\n",
    "    #             [True, False, True]]\n",
    "    #no_masks = [[False] * 3, [False] * 3]\n",
    "    \n",
    "num_mir=1296\n",
    "num_disease=11783\n",
    "num_gene=10116\n",
    "    \n",
    "expected_metapaths = [\n",
    "    [(0, 1, 0), (0, 1, 2, 1, 0), (0,2,2,0)],\n",
    "    [(1, 0, 1), (1, 2, 1), (1, 2, 2, 1)]\n",
    "    ]\n",
    "    # f='hidden90_sample140.txt'\n",
    "    \n",
    "dataset_path = \"dataset/\"\n",
    "log_info_path='log_info.txt'\n",
    "    \n",
    "def run_model_OURS(feats_type, hidden_dim, num_heads, attn_vec_dim,\n",
    "                     num_epochs, patience, batch_size, neighbor_samples, repeat,save_postfix):\n",
    "    adjlists_ua, edge_metapath_indices_list_ua, _, type_mask, train_val_test_pos_user_artist, train_val_test_neg_user_artist = load_LastFM_data(dataset_path)\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    features_list = []\n",
    "    in_dims = []\n",
    "    if feats_type == 0:\n",
    "        for i in range(num_ntype):\n",
    "            dim = (type_mask == i).sum()\n",
    "            in_dims.append(dim)\n",
    "            indices = np.vstack((np.arange(dim), np.arange(dim)))\n",
    "            indices = torch.LongTensor(indices)\n",
    "            values = torch.FloatTensor(np.ones(dim))\n",
    "            features_list.append(torch.sparse.FloatTensor(indices, values, torch.Size([dim, dim])).to(device))\n",
    "    elif feats_type == 1:\n",
    "        for i in range(num_ntype):\n",
    "            dim = 10\n",
    "            num_nodes = (type_mask == i).sum()\n",
    "            in_dims.append(dim)\n",
    "            features_list.append(torch.zeros((num_nodes, 10)).to(device))\n",
    "    train_pos_user_artist = train_val_test_pos_user_artist['train_pos_mir_disease']\n",
    "    val_pos_user_artist = train_val_test_pos_user_artist['val_pos_mir_disease']\n",
    "    test_pos_user_artist = train_val_test_pos_user_artist['test_pos_mir_disease']\n",
    "    train_neg_user_artist = train_val_test_neg_user_artist['train_neg_mir_disease']\n",
    "    val_neg_user_artist = train_val_test_neg_user_artist['val_neg_mir_disease']\n",
    "    test_neg_user_artist = train_val_test_neg_user_artist['test_neg_mir_disease']\n",
    "    y_true_test = np.array([1] * len(test_pos_user_artist) + [0] * len(test_neg_user_artist))\n",
    "\n",
    "    auc_list = []\n",
    "    ap_list = []\n",
    "\n",
    "   # with open(f,\"a\") as file:\n",
    "   #     file.write('单层dropout0.6+torch.mm(features,self.weight)'+\"\\n\")\n",
    "    for _ in range(repeat):\n",
    "        net = MAGNN_lp(\n",
    "            [3, 3], 6, etypes_lists, in_dims, hidden_dim, hidden_dim, num_heads, attn_vec_dim, dropout_rate)\n",
    "        net.to(device)\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        # training loop\n",
    "        net.train()\n",
    "        early_stopping = EarlyStopping(patience=patience,log_path=log_info_path, verbose=True, save_path='checkpoint01/checkpoint_{}.pt'.format(save_postfix))\n",
    "        dur1 = []\n",
    "        dur2 = []\n",
    "        dur3 = []\n",
    "        train_pos_idx_generator = index_generator(batch_size=batch_size, num_data=len(train_pos_user_artist))\n",
    "        val_idx_generator = index_generator(batch_size=batch_size, num_data=len(val_pos_user_artist), shuffle=False)\n",
    "        for epoch in range(num_epochs):\n",
    "            t_start = time.time()\n",
    "            # training\n",
    "            net.train()\n",
    "            for iteration in range(train_pos_idx_generator.num_iterations()):\n",
    "                # forward\n",
    "                t0 = time.time()\n",
    "\n",
    "                train_pos_idx_batch = train_pos_idx_generator.next()\n",
    "                train_pos_idx_batch.sort()\n",
    "               \n",
    "                train_pos_user_artist_batch = train_pos_user_artist[train_pos_idx_batch].tolist()\n",
    "                train_neg_idx_batch = np.random.choice(len(train_neg_user_artist), len(train_pos_idx_batch))\n",
    "                train_neg_idx_batch.sort()\n",
    "                train_neg_user_artist_batch = train_neg_user_artist[train_neg_idx_batch].tolist()\n",
    "                \n",
    "                #shuffle\n",
    "                num_pos = train_pos_idx_batch.shape[0]\n",
    "                train_batch = np.concatenate([train_pos_user_artist_batch, train_neg_user_artist_batch], axis=0)\n",
    "                y_label = np.zeros((train_batch.shape[0], 1), dtype=int)\n",
    "                y_label[:num_pos] = 1\n",
    "                train_data = np.concatenate([train_batch, y_label], axis=1)\n",
    "                np.random.shuffle(train_data)\n",
    "                train_batch = train_data[:, :-1]\n",
    "                y_label = train_data[:, -1]\n",
    "\n",
    "                train_g_lists, train_indices_lists, train_idx_batch_mapped_lists ,node_lists= parse_minibatch_LastFM(\n",
    "                   adjlists_ua, edge_metapath_indices_list_ua, train_batch, device, neighbor_samples, no_masks, num_mir)\n",
    "                t1 = time.time()\n",
    "                dur1.append(t1 - t0)\n",
    "\n",
    "                [embedding_user, embedding_artist], _ = net(\n",
    "                    (train_g_lists, features_list, type_mask, train_indices_lists, train_idx_batch_mapped_lists,node_lists))\n",
    "                \n",
    "                embedding_user = embedding_user.view(-1, 1, embedding_user.shape[1])\n",
    "                embedding_artist = embedding_artist.view(-1, embedding_artist.shape[1], 1)\n",
    "                \n",
    "                out = torch.bmm(embedding_user, embedding_artist)\n",
    "                class_op = torch.LongTensor([1 if l == 1 else -1 for l in y_label]).view(-1, 1, 1).to(device)\n",
    "                \n",
    "                train_loss = -torch.mean(F.logsigmoid(out * class_op))#-torch.mean(F.logsigmoid(net.get_loss()*0.5))\n",
    "                \n",
    "                t2 = time.time()\n",
    "                dur2.append(t2 - t1)\n",
    "\n",
    "                # autograd\n",
    "                optimizer.zero_grad()\n",
    "                train_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                t3 = time.time()\n",
    "                dur3.append(t3 - t2)\n",
    "\n",
    "                # print training info\n",
    "                if iteration % 100 == 0:\n",
    "                    print(\n",
    "                        'Epoch {:05d} | Iteration {:05d} | Train_Loss {:.4f} | Time1(s) {:.4f} | Time2(s) {:.4f} | Time3(s) {:.4f}'.format(\n",
    "                            epoch, iteration, train_loss.item(), np.mean(dur1), np.mean(dur2), np.mean(dur3)))\n",
    "                    with open(log_info_path,\"a\") as file:\n",
    "                        file.write('epoch:'+str(epoch)+'iteration:'+str(iteration)+'train_loss:'+str(train_loss.item())+\"time1:\"+ str(np.mean(dur1))+'time2'\n",
    "                               +str(np.mean(dur2))+'time3'+str(np.mean(dur3))+\"\\n\")    \n",
    "            # validation\n",
    "            net.eval()\n",
    "            val_loss = []\n",
    "            with torch.no_grad():\n",
    "                for iteration in range(val_idx_generator.num_iterations()):\n",
    "                    # forward\n",
    "                    val_idx_batch = val_idx_generator.next()\n",
    "                    val_pos_user_artist_batch = val_pos_user_artist[val_idx_batch].tolist()\n",
    "                    val_neg_user_artist_batch = val_neg_user_artist[val_idx_batch].tolist()\n",
    "                    val_pos_g_lists, val_pos_indices_lists, val_pos_idx_batch_mapped_lists,val_pos_node_lists = parse_minibatch_LastFM(\n",
    "                        adjlists_ua, edge_metapath_indices_list_ua, val_pos_user_artist_batch, device, neighbor_samples, no_masks, num_mir)\n",
    "                    val_neg_g_lists, val_neg_indices_lists, val_neg_idx_batch_mapped_lists,val_neg_node_lists= parse_minibatch_LastFM(\n",
    "                        adjlists_ua, edge_metapath_indices_list_ua, val_neg_user_artist_batch, device, neighbor_samples, no_masks, num_mir)\n",
    "\n",
    "                    [pos_embedding_user, pos_embedding_artist], _ = net(\n",
    "                        (val_pos_g_lists, features_list, type_mask, val_pos_indices_lists, val_pos_idx_batch_mapped_lists,val_pos_node_lists))\n",
    "                    [neg_embedding_user, neg_embedding_artist], _ = net(\n",
    "                        (val_neg_g_lists, features_list, type_mask, val_neg_indices_lists, val_neg_idx_batch_mapped_lists,val_neg_node_lists))\n",
    "                    pos_embedding_user = pos_embedding_user.view(-1, 1, pos_embedding_user.shape[1])\n",
    "                    pos_embedding_artist = pos_embedding_artist.view(-1, pos_embedding_artist.shape[1], 1)\n",
    "                    neg_embedding_user = neg_embedding_user.view(-1, 1, neg_embedding_user.shape[1])\n",
    "                    neg_embedding_artist = neg_embedding_artist.view(-1, neg_embedding_artist.shape[1], 1)\n",
    "\n",
    "                    pos_out = torch.bmm(pos_embedding_user, pos_embedding_artist)\n",
    "                    neg_out = -torch.bmm(neg_embedding_user, neg_embedding_artist)\n",
    "                    val_loss.append(-torch.mean(F.logsigmoid(pos_out) + F.logsigmoid(neg_out)))#-torch.mean(F.logsigmoid(net.get_loss()*0.5)))\n",
    "                val_loss = torch.mean(torch.tensor(val_loss))\n",
    "            t_end = time.time()\n",
    "            # print validation info\n",
    "            print('Epoch {:05d} | Val_Loss {:.4f} | Time(s) {:.4f}'.format(\n",
    "                epoch, val_loss.item(), t_end - t_start))\n",
    "            \n",
    "            with open(log_info_path,\"a\") as file:\n",
    "                file.write('epoch:'+str(epoch)+'val_loss:'+str(val_loss.item())+\"time:\"+str(t_end-t_start)+\"\\n\")\n",
    "            # early stopping\n",
    "            early_stopping(val_loss, net)\n",
    "            if early_stopping.early_stop:\n",
    "                print('Early stopping!')\n",
    "                with open(log_info_path,\"a\") as file:\n",
    "                    file.write('epoch:'+str(epoch)+'early stopping!'+\"\\n\")\n",
    "                break\n",
    "            \n",
    "        test_idx_generator = index_generator(batch_size=batch_size, num_data=len(test_pos_user_artist), shuffle=False)\n",
    "        net.load_state_dict(torch.load('checkpoint01/checkpoint_{}.pt'.format(save_postfix)))\n",
    "        net.eval()\n",
    "        pos_proba_list = []\n",
    "        neg_proba_list = []\n",
    "        with torch.no_grad():\n",
    "            for iteration in range(test_idx_generator.num_iterations()):\n",
    "                # forward\n",
    "                test_idx_batch = test_idx_generator.next()\n",
    "                test_pos_user_artist_batch = test_pos_user_artist[test_idx_batch].tolist()\n",
    "                test_neg_user_artist_batch = test_neg_user_artist[test_idx_batch].tolist()\n",
    "                test_pos_g_lists, test_pos_indices_lists, test_pos_idx_batch_mapped_lists,test_pos_node_lists = parse_minibatch_LastFM(\n",
    "                    adjlists_ua, edge_metapath_indices_list_ua, test_pos_user_artist_batch, device, neighbor_samples, no_masks, num_mir)\n",
    "                test_neg_g_lists, test_neg_indices_lists, test_neg_idx_batch_mapped_lists,test_neg_node_lists = parse_minibatch_LastFM(\n",
    "                    adjlists_ua, edge_metapath_indices_list_ua, test_neg_user_artist_batch, device, neighbor_samples, no_masks, num_mir)\n",
    "\n",
    "                [pos_embedding_user, pos_embedding_artist], _ = net(\n",
    "                    (test_pos_g_lists, features_list, type_mask, test_pos_indices_lists, test_pos_idx_batch_mapped_lists,test_pos_node_lists))\n",
    "                \n",
    "                [neg_embedding_user, neg_embedding_artist], _ = net(\n",
    "                    (test_neg_g_lists, features_list, type_mask, test_neg_indices_lists, test_neg_idx_batch_mapped_lists,test_neg_node_lists))\n",
    "                pos_embedding_user = pos_embedding_user.view(-1, 1, pos_embedding_user.shape[1])\n",
    "                pos_embedding_artist = pos_embedding_artist.view(-1, pos_embedding_artist.shape[1], 1)\n",
    "                neg_embedding_user = neg_embedding_user.view(-1, 1, neg_embedding_user.shape[1])\n",
    "                neg_embedding_artist = neg_embedding_artist.view(-1, neg_embedding_artist.shape[1], 1)\n",
    "\n",
    "                pos_out = torch.bmm(pos_embedding_user, pos_embedding_artist).flatten()\n",
    "                neg_out = torch.bmm(neg_embedding_user, neg_embedding_artist).flatten()\n",
    "                pos_proba_list.append(torch.sigmoid(pos_out))\n",
    "                neg_proba_list.append(torch.sigmoid(neg_out))\n",
    "            y_proba_test = torch.cat(pos_proba_list + neg_proba_list)\n",
    "            y_proba_test = y_proba_test.cpu().numpy()\n",
    "        np.savez('MEAHNE_prediction_result.npz', y_true=y_true_test,\n",
    "                y_pred=y_proba_test)    \n",
    "        auc = roc_auc_score(y_true_test, y_proba_test)\n",
    "        ap = average_precision_score(y_true_test, y_proba_test)\n",
    "        print('Link Prediction Test')\n",
    "        print('AUC = {}'.format(auc))\n",
    "        print('AP = {}'.format(ap))\n",
    "        auc_list.append(auc)\n",
    "        ap_list.append(ap)\n",
    "        with open(log_info_path,\"a\") as file:\n",
    "                file.write('Link Prediction Test:'+\"\\n\"+'AUC = {}:'+str(auc)+\"|\"+\"AP = {}:\"+str(ap)+\"\\n\")\n",
    "    print('----------------------------------------------------------------')\n",
    "    print('Link Prediction Tests Summary')\n",
    "    print('AUC_mean = {}, AUC_std = {}'.format(np.mean(auc_list), np.std(auc_list)))\n",
    "    print('AP_mean = {}, AP_std = {}'.format(np.mean(ap_list), np.std(ap_list)))\n",
    "    with open(log_info_path,\"a\") as file:\n",
    "        file.write('Link Prediction Tests Summary:'+\"\\n\"+\"AUC_mean = {}\"+str(np.mean(auc_list))+'AUC_std = {}'+str(np.std(auc_list))+\n",
    "                           \"\\n\"+'AP_mean = {} '+str(np.mean(ap_list))+'AP_std = {}'+str(np.std(ap_list))+\"\\n\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_model_OURS(0, 64,  1,128, 100,3,16,60,3, 'MEAHNE')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-subscriber",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:workspace] *",
   "language": "python",
   "name": "conda-env-workspace-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
